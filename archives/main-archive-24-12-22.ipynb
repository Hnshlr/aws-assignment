{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cloud Computing Assignment 2022-2023\n",
    "Implementation of an application processing large data sets in parallel on a distributed Cloud environment (ie. AWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Solution setup - Pre-requisites:\n",
    "1. Make sure the aws credentials taken from the Learner Lab are updated in the ~/.aws/credentials file (Test connection locally using aws sts get-caller-identity)\n",
    "2. Specify the \"labsuser.pem\" perm-key's (taken from the Learner Lab) path, needed by paramiko to connect to the EC2 instances and execute ssh commands.\n",
    "3. Create EC2, S3 and SQS resources and clients using boto3.\n",
    "### Solution setup steps (Using Boto3):\n",
    "1. Create a cluster of EC2 instances on AWS, using the AWS Linux 2 images.\n",
    "2. Create a S3 bucket to store the data.\n",
    "3. Create a SQS queue to store stacks of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### IMPORTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "import numpy as np\n",
    "import paramiko\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CONFIGURATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Permission key:\n",
    "pem_key = 'learner-lab-cfg/labsuser.pem'\n",
    "# Create an EC2 resource (higher level abstraction than a client):\n",
    "ec2 = boto3.resource('ec2')\n",
    "# Create a S3 resource:\n",
    "s3 = boto3.resource('s3')\n",
    "# Create a SQS resource:\n",
    "sqs = boto3.resource('sqs')\n",
    "# Create a SSM resource:\n",
    "ssm_client = boto3.client('ssm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### BOTO 3 - APP INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get boto3 session credentials, successfully authenticated using updated local credentials:\n",
    "def get_boto3_session_credentials():\n",
    "    session = boto3.session.Session()\n",
    "    credentials = session.get_credentials()\n",
    "    return credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SSM - APP INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# EXECUTE SSH COMMAND ON INSTANCE USING SSM - BY INSTANCE ID:\n",
    "def exec_SSH_on_instance_using_SSM(instance_id, command):\n",
    "    response = ssm_client.send_command(\n",
    "        InstanceIds=[instance_id],\n",
    "        DocumentName='AWS-RunShellScript',\n",
    "        Parameters={'commands': [command]}\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SQS - APP INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CREATE SQS QUEUE:\n",
    "def create_sqs_queue(queue_name):\n",
    "    try:\n",
    "        queue = sqs.create_queue(\n",
    "            QueueName=queue_name,\n",
    "            Attributes={\n",
    "                'FifoQueue': 'true',\n",
    "                'MessageRetentionPeriod': '86400',\n",
    "                'ContentBasedDeduplication': 'true'\n",
    "            }\n",
    "        )\n",
    "        return queue\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# CREATE MULTIPLE SQS QUEUES - AND WAIT FOR ALL TO BE CREATED:\n",
    "def create_sqs_queues(queue_names):\n",
    "    queues = []\n",
    "    for i in range(len(queue_names)):\n",
    "        try:\n",
    "            queue = create_sqs_queue(queue_names[i])\n",
    "            queues.append(queue)\n",
    "            print(i+1,'/',len(queue_names),': Created queue: ', queue_names[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "# DELETE SQS QUEUE:\n",
    "def delete_sqs_queue(queue_name):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        queue.delete()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "# GET ALL SQS QUEUES:\n",
    "def get_all_sqs_queues():\n",
    "    queues = []\n",
    "    for queue in sqs.queues.all():\n",
    "        queues.append(queue)\n",
    "    return queues\n",
    "\n",
    "# VIEW ALL SQS QUEUES:\n",
    "def view_all_sqs_queues():\n",
    "    queues = get_all_sqs_queues()\n",
    "    for queue in queues:\n",
    "        print(queue.url)\n",
    "\n",
    "# GET QUEUE STATUS:\n",
    "def get_queue_attributes(queue_name):\n",
    "    queue_attributes = sqs.get_queue_by_name(QueueName=queue_name).attributes\n",
    "    return queue_attributes\n",
    "\n",
    "# SEND MESSAGE TO SQS QUEUE:\n",
    "def send_message_to_sqs_queue(queue_name, message, group_id):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        response = queue.send_message(\n",
    "            MessageBody=message,\n",
    "            MessageGroupId=group_id\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# BULK SEND MESSAGES TO SQS QUEUE, AND CONTROL RESPONSE:\n",
    "def send_bulk_messages_to_sqs_queue(queue_name, messages, group_id):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    for i in range(0, len(messages)):\n",
    "        response = queue.send_message(\n",
    "            MessageBody=messages[i],\n",
    "            MessageGroupId=group_id\n",
    "        )\n",
    "        # print(response)\n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] != 200 or 'connection' in response['ResponseMetadata']['HTTPHeaders']:\n",
    "            # print('ERROR: Failed to send message to SQS queue! Retrying now...')\n",
    "            while response['ResponseMetadata']['HTTPStatusCode'] != 200 or 'connection' in response['ResponseMetadata']['HTTPHeaders']:\n",
    "                response = queue.send_message(\n",
    "                    MessageBody=messages[i],\n",
    "                    MessageGroupId=group_id\n",
    "                )\n",
    "                # print(response)\n",
    "                if response['ResponseMetadata']['HTTPStatusCode'] == 200 and 'connection' not in response['ResponseMetadata']['HTTPHeaders']:\n",
    "                    break\n",
    "        print('Step '+str(i+1)+'/'+str(len(messages))+' done.')\n",
    "\n",
    "# GET LAST 10 MESSAGES FROM SQS QUEUE:\n",
    "def get_last_ten_messages_from_sqs_queue(queue_name, flight_time):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        messages = queue.receive_messages(\n",
    "            MaxNumberOfMessages=10,\n",
    "            VisibilityTimeout=flight_time\n",
    "        )\n",
    "        return messages\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# GET LAST MESSAGE FROM SQS QUEUE:\n",
    "def get_last_message_from_sqs_queue(queue_name, flight_time):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        messages = queue.receive_messages(\n",
    "            MaxNumberOfMessages=1,\n",
    "            VisibilityTimeout=flight_time\n",
    "        )\n",
    "        return messages\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# GET THE AMOUNT OF AVAILABLE MESSAGES IN SQS QUEUE:\n",
    "def get_amount_of_available_messages_in_sqs_queue(queue_name):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        amount = queue.attributes['ApproximateNumberOfMessages']\n",
    "        return int(amount)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# GET THE AMOUNT OF IN-FLIGHT MESSAGES IN SQS QUEUE:\n",
    "def get_amount_of_in_flight_messages_in_sqs_queue(queue_name):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        amount = queue.attributes['ApproximateNumberOfMessagesNotVisible']\n",
    "        return int(amount)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# DELETE MESSAGE FROM SQS QUEUE - BY RECEIPT HANDLE:\n",
    "def delete_message_from_sqs_queue(queue_name, receipt_handle):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        response = queue.delete_messages(\n",
    "            Entries=[\n",
    "                {\n",
    "                    'Id': '1',\n",
    "                    'ReceiptHandle': receipt_handle\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# GET MAX MESSAGE SIZE FROM SQS QUEUE - IN BYTES:\n",
    "def get_max_message_size_from_sqs_queue(queue_name):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        attributes = queue.attributes\n",
    "        return int(attributes['MaximumMessageSize'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# PURGE SQS QUEUE:\n",
    "def purge_queue(queue_name):\n",
    "    try:\n",
    "        queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "        queue.purge()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### S3 - APP INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CREATE S3 BUCKET:\n",
    "def create_s3_bucket(bucket_name):\n",
    "    try:\n",
    "        s3.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            ObjectOwnership='BucketOwnerPreferred'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return s3.Bucket(bucket_name)\n",
    "\n",
    "# DELETE S3 BUCKET:\n",
    "def delete_s3_bucket(bucket_name):\n",
    "    try:\n",
    "        bucket = s3.Bucket(bucket_name)\n",
    "        bucket.objects.all().delete()\n",
    "        bucket.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# PRINT S3 BUCKET DETAILS:\n",
    "def print_s3_bucket_details(bucket):\n",
    "    print(\"{name=%s, creation_date=%s}\" % (bucket.name, bucket.creation_date))\n",
    "\n",
    "# VIEW ALL S3 BUCKETS:\n",
    "def view_all_s3_buckets():\n",
    "    for bucket in s3.buckets.all():\n",
    "        print_s3_bucket_details(bucket)\n",
    "\n",
    "# UPLOAD LOCAL FILE TO S3 BUCKET:\n",
    "def upload_local_file_to_s3(filename, bucketname, destination_path):\n",
    "    s3.Bucket(bucketname).upload_file(filename, destination_path+filename)\n",
    "\n",
    "# DELETE FILE FROM S3 BUCKET:\n",
    "def delete_file_from_s3(filename, bucketname, path):\n",
    "    s3.Bucket(bucketname).Object(path+filename).delete()\n",
    "\n",
    "# DELETE DIRECTORY FROM S3 BUCKET:\n",
    "def delete_directory_from_s3_bucket(bucket_name, directory_name):\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    bucket.objects.filter(Prefix=directory_name).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### EC2 - APP INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# START ALL EC2 INSTANCES:\n",
    "def start_all_instances():\n",
    "    # Start all instances:\n",
    "    for instance in ec2.instances.filter(Filters=[{'Name': 'instance-state-name', 'Values': ['stopped']}]):\n",
    "        instance.start()\n",
    "        print('Starting instance: ', instance.id, instance.tags[0]['Value'])\n",
    "\n",
    "# STOP EC2 INSTANCE - BY NAME:\n",
    "def stop_instance_by_name(instance_name):\n",
    "    # Stop instance by name:\n",
    "    for instance in ec2.instances.filter(Filters=[{'Name': 'tag:Name', 'Values': [instance_name], 'Name': 'instance-state-name', 'Values': ['running']}]):\n",
    "        instance.stop()\n",
    "        print('Stopping instance: ', instance.id, instance.tags[0]['Value'])\n",
    "\n",
    "# STOP ALL EC2 INSTANCES:\n",
    "def stop_all_instances():\n",
    "    # Stop all instances:\n",
    "    for instance in ec2.instances.filter(Filters=[{'Name': 'instance-state-name', 'Values': ['running']}]):\n",
    "        instance.stop()\n",
    "        print('Stopping instance: ', instance.id, instance.tags[0]['Value'])\n",
    "\n",
    "# PRINT EC2 INSTANCE DETAILS:\n",
    "def print_instance_details(instance):\n",
    "    print(\"{id=%s, name=%s, state=%s, type=%s}\" % (instance.id, instance.tags[0]['Value'], instance.state['Name'], instance.instance_type))\n",
    "\n",
    "# VIEW ALL EC2 INSTANCES:\n",
    "def view_all_instances(include_terminated):\n",
    "    # Print instance ID, name, state, and type:\n",
    "    for instance in ec2.instances.all():\n",
    "        if include_terminated or instance.state['Name'] != 'terminated':\n",
    "            print_instance_details(instance)\n",
    "\n",
    "# VIEW ALL EC2 INSTANCES - BY STATE FILTER:\n",
    "def view_instances_by_state(state):\n",
    "    # Print instance ID, name, state, and type; who are running\n",
    "    for instance in ec2.instances.filter(Filters=[{'Name': 'instance-state-name', 'Values': [state]}]):\n",
    "        print_instance_details(instance)\n",
    "\n",
    "# TERMINATE ALL EC2 INSTANCES:\n",
    "def terminate_all_instances():\n",
    "    # Terminate all instances:\n",
    "    for instance in ec2.instances.all():\n",
    "        if instance.state['Name'] != 'terminated':\n",
    "            instance.terminate()\n",
    "            print('Terminated instance: ', instance.id, instance.tags[0]['Value'])\n",
    "\n",
    "# TERMINATE EC2 INSTANCE - BY NAME:\n",
    "def terminate_instance_by_name(name):\n",
    "    for instance in ec2.instances.all():\n",
    "        if instance.tags[0]['Value'] == name and instance.state['Name'] != 'terminated':\n",
    "            instance.terminate()\n",
    "            print('Terminated instance: ', instance.id, instance.tags[0]['Value'])\n",
    "\n",
    "# CREATE INSTANCE - BY NAME, USING \"amazon linux 2\" AMI, \"t2.micro\" INSTANCE TYPE, \"vockey\" KEY PAIR, AND \"default\" SECURITY GROUP:\n",
    "def create_instance(name):\n",
    "    ec2.create_instances(\n",
    "        ImageId='ami-0b0dcb5067f052a63',\n",
    "        MinCount=1,\n",
    "        MaxCount=1,\n",
    "        InstanceType='t2.micro',\n",
    "        KeyName='vockey',\n",
    "        SecurityGroupIds=['sg-0f52fa9fe5477133b'],\n",
    "        TagSpecifications=[\n",
    "            {\n",
    "                'ResourceType': 'instance',\n",
    "                'Tags': [\n",
    "                    {\n",
    "                        'Key': 'Name',\n",
    "                        'Value': name\n",
    "                    },\n",
    "                ]\n",
    "            },\n",
    "        ],\n",
    "        IamInstanceProfile={\n",
    "                       'Arn': 'arn:aws:iam::868429207081:instance-profile/LabInstanceProfile'\n",
    "                   },\n",
    "    )\n",
    "\n",
    "# CREATE MULTIPLES INSTANCES - BY NAME, USING \"amazon linux 2\" AMI, \"t2.micro\" INSTANCE TYPE, \"vockey\" KEY PAIR, AND \"default\" SECURITY GROUP:\n",
    "def create_instances_and_wait_for_running(names):\n",
    "    for name in names:\n",
    "        create_instance(name)\n",
    "    print('All instances created. Waiting for them to be running...')\n",
    "    # Filter for instances with the given names:\n",
    "    instances = ec2.instances.filter(Filters=[{'Name': 'tag:Name', 'Values': names}, {'Name': 'instance-state-name', 'Values': ['pending']}])\n",
    "    amount = 0\n",
    "    while len(list(instances)) > 0:\n",
    "        if amount != len(list(instances)):\n",
    "            print('Remaining instances: ', len(list(instances)))\n",
    "            amount = len(list(instances))\n",
    "        time.sleep(1)\n",
    "        instances = ec2.instances.filter(Filters=[{'Name': 'tag:Name', 'Values': names}, {'Name': 'instance-state-name', 'Values': ['pending']}])\n",
    "    print('All instances are running.')\n",
    "\n",
    "# UPDATE INSTANCE AWS CREDENTIALS:\n",
    "def update_instance_credentials_using_boto3_session_credentials(instance_name):\n",
    "    exec_SSH_on_instance(instance_name, 'aws configure set aws_access_key_id '+get_boto3_session_credentials().access_key)\n",
    "    exec_SSH_on_instance(instance_name, 'aws configure set aws_secret_access_key '+get_boto3_session_credentials().secret_key)\n",
    "    exec_SSH_on_instance(instance_name, 'aws configure set aws_session_token '+get_boto3_session_credentials().token)\n",
    "    exec_SSH_on_instance(instance_name, 'aws configure set region us-east-1')\n",
    "\n",
    "# GET INSTANCE ID - BY NAME:\n",
    "def get_instance_id_by_name(name):\n",
    "    for instance in ec2.instances.all():\n",
    "        if instance.tags[0]['Value'] == name and instance.state['Name'] != 'terminated':\n",
    "            return instance.id\n",
    "\n",
    "# GET INSTANCE PUBLIC IP - BY NAME:\n",
    "def get_instance_public_dns_by_name(name):\n",
    "    for instance in ec2.instances.all():\n",
    "        if instance.tags[0]['Value'] == name and instance.state['Name'] != 'terminated':\n",
    "            return instance.public_dns_name\n",
    "\n",
    "# GET INSTANCE PUBLIC IP - BY NAME:\n",
    "def get_instance_public_ip_by_name(name):\n",
    "    for instance in ec2.instances.all():\n",
    "        if instance.tags[0]['Value'] == name and instance.state['Name'] != 'terminated':\n",
    "            return instance.public_ip_address\n",
    "\n",
    "# GET INSTANCE PUBLIC IP - BY ID:\n",
    "def get_instance_public_dns_by_id(instance_id):\n",
    "    for instance in ec2.instances.all():\n",
    "        if instance.id == instance_id:\n",
    "            return instance.public_dns_name\n",
    "\n",
    "# EXECUTE SSH COMMAND ON INSTANCE - BY NAME:\n",
    "def exec_SSH_on_instance(instance_name, command):\n",
    "    paramiko_key = paramiko.RSAKey.from_private_key_file(pem_key)\n",
    "    client = paramiko.SSHClient()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    try:\n",
    "        client.connect(hostname=get_instance_public_dns_by_id(get_instance_id_by_name(instance_name)), username='ec2-user', pkey=paramiko_key)\n",
    "        stdin, stdout, stderr = client.exec_command(command)\n",
    "        return stdout.read(), stderr.read()\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SPARK - APP INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# WORK IN PROGRESS ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# name = \"master\"\n",
    "#\n",
    "# # Create a SparkSession:\n",
    "# # TODO: WIP\n",
    "# spark = SparkSession.builder.master(\"spark://\" + get_instance_public_ip_by_name(name) + \":7077\").getOrCreate()\n",
    "# sc = spark.sparkContext\n",
    "# sc.setLogLevel(\"OFF\")\n",
    "# sc.uiWebUrl\n",
    "#\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MATRIX - FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a matrix of nxn size:\n",
    "def create_random_square_matrix(n):\n",
    "    return np.random.randint(0, 10, size=(n, n))\n",
    "\n",
    "# Split the matrix in blocks until the size of combined blocks is less than max_message_size:\n",
    "def find_optimal_blocks_amount(matrix, max_message_size):\n",
    "    matrix_body = {\n",
    "        'i': 1,\n",
    "        'j': 1,\n",
    "        'temp-slice': matrix.tolist()\n",
    "    }\n",
    "    matrix_size = len(json.dumps(matrix_body))\n",
    "    min_blocks_amount = 1\n",
    "    for i in range(2, 10000):\n",
    "        block_size = matrix_size / i**2\n",
    "        amount_of_blocks_per_message = 2*i\n",
    "        message_size = block_size * amount_of_blocks_per_message\n",
    "        if message_size < max_message_size and matrix.shape[0] % i < np.round(matrix.shape[0] / i):\n",
    "            min_blocks_amount = i**2\n",
    "            break\n",
    "    return min_blocks_amount\n",
    "\n",
    "# Split matrix into blocks:\n",
    "def split_matrix_in_blocks(matrix, amount_of_blocks):\n",
    "    side_size = np.sqrt(amount_of_blocks)\n",
    "    if not side_size.is_integer():\n",
    "        raise ValueError('ERROR: Amount of blocks must be a square number!')\n",
    "    else:\n",
    "        if matrix.shape[0] % side_size != 0:\n",
    "            pad = np.floor(matrix.shape[0] / side_size)\n",
    "            sub_matrices = np.empty((int(side_size)+1, int(side_size)+1), dtype=np.ndarray)\n",
    "            for i in range(0, sub_matrices.shape[0]-1):\n",
    "                for j in range(0, sub_matrices.shape[0]-1):\n",
    "                    sub_matrices[i][j] = matrix[int(i * pad):int((i + 1) * pad), int(j * pad):int((j + 1) * pad)]\n",
    "            for i in range(0, sub_matrices.shape[0]-1):\n",
    "                sub_matrices[i][sub_matrices.shape[0]-1] = matrix[int(i * pad):int((i + 1) * pad), int((sub_matrices.shape[0]-1) * pad):]\n",
    "            for j in range(0, sub_matrices.shape[0]-1):\n",
    "                sub_matrices[sub_matrices.shape[0]-1][j] = matrix[int((sub_matrices.shape[0]-1) * pad):, int(j * pad):int((j + 1) * pad)]\n",
    "            sub_matrices[sub_matrices.shape[0]-1][sub_matrices.shape[0]-1] = matrix[int((sub_matrices.shape[0]-1) * pad):, int((sub_matrices.shape[0]-1) * pad):]\n",
    "        else:\n",
    "            sub_matrices = np.empty((int(side_size), int(side_size)), dtype=np.ndarray)\n",
    "            pad = matrix.shape[0] / side_size\n",
    "            for i in range(0, sub_matrices.shape[0]):\n",
    "                for j in range(0, sub_matrices.shape[0]):\n",
    "                    sub_matrices[i][j] = matrix[int(i * pad):int((i + 1) * pad), int(j * pad):int((j + 1) * pad)]\n",
    "    return sub_matrices\n",
    "\n",
    "# Compute a single block:\n",
    "def compute_single_block(A, B, i, j, size):\n",
    "    block = np.dot(\n",
    "        np.concatenate([A[i][k] for k in range(size)], axis=1),\n",
    "        np.concatenate([B[k][j] for k in range(size)], axis=0)\n",
    "    )\n",
    "    return block\n",
    "\n",
    "# Multiply two matrices:\n",
    "def multiply_matrices(matrix1, matrix2, amount_of_blocks):\n",
    "    # Split matrices into blocks:\n",
    "    A = split_matrix_in_blocks(matrix1, amount_of_blocks)\n",
    "    B = split_matrix_in_blocks(matrix2, amount_of_blocks)\n",
    "    result = np.empty((A.shape[0], B.shape[1]), dtype=np.ndarray)\n",
    "    size = A.shape[0]\n",
    "    for i in range(0, result.shape[0]):\n",
    "        for j in range(0, result.shape[1]):\n",
    "            result[i][j] = compute_single_block(A, B, i, j, size)\n",
    "    result = np.concatenate([np.concatenate([result[i][j] for j in range(size)], axis=1) for i in range(size)], axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AWS - SOLUTION SETUP AND TASKS EXECUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SETTINGS=\n",
    "worker_amount = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# EC2 INSTANCES:\n",
    "# instances_names = np.concatenate((np.array(['master']), np.array(['worker' + str(i) for i in range(1, worker_amount+1)]))).tolist()\n",
    "# create_instances_and_wait_for_running(instances_names)\n",
    "# SQS QUEUES:\n",
    "queues_names = ['main-protected-jobss.fifo', 'main-protected-resultss.fifo']\n",
    "create_sqs_queues(queues_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "view_all_instances(False)\n",
    "view_all_sqs_queues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_amount_of_in_flight_messages_in_sqs_queue(queues_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CREATE A MATRIX - GIVING THE SIDE SIZE:\n",
    "matrix_shape = 500\n",
    "matrix = create_random_square_matrix(matrix_shape)\n",
    "\n",
    "# SPLIT MATRIX INTO BLOCKS - USING OPTIMAL BLOCKS AMOUNT:\n",
    "max_SQS_msg_size = get_max_message_size_from_sqs_queue(queues_names[0])\n",
    "blocks = split_matrix_in_blocks(matrix, find_optimal_blocks_amount(matrix, max_SQS_msg_size))\n",
    "\n",
    "# STORE IN AN ARRAY THE SLICES REQUIRED TO COMPUTE EACH BLOCK OF THE RESULT MATRIX:\n",
    "slices = np.empty((blocks.shape[0], blocks.shape[1], 3), dtype=np.ndarray)\n",
    "for i in range(0, blocks.shape[0]):\n",
    "    for j in range(0, blocks.shape[1]):\n",
    "        slices[i][j][0] = np.concatenate([blocks[i][k] for k in range(blocks.shape[0])], axis=1)\n",
    "        slices[i][j][1] = np.concatenate([blocks[k][j] for k in range(blocks.shape[0])], axis=0)\n",
    "\n",
    "# CREATE A LIST OF MESSAGES TO SEND TO SQS QUEUE:\n",
    "messages = []\n",
    "for i in range(0, blocks.shape[0]):\n",
    "    for j in range(0, blocks.shape[1]):\n",
    "        message_body = {\n",
    "            'i': i,\n",
    "            'j': j,\n",
    "            'left-slice': slices[i][j][0].tolist(),\n",
    "            'right-slice': slices[i][j][1].tolist()\n",
    "        }\n",
    "        json_message_body = json.dumps(message_body)\n",
    "        messages.append(json_message_body)\n",
    "\n",
    "# BULK SEND MESSAGES TO THE \"JOBS\" QUEUE:\n",
    "send_bulk_messages_to_sqs_queue(queues_names[0], messages, 'work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gather_jobs_then_compute_and_send_results(jobs_queue_name, results_queue_name):\n",
    "    while get_amount_of_in_flight_messages_in_sqs_queue(jobs_queue_name) > 0 or get_amount_of_available_messages_in_sqs_queue(jobs_queue_name) > 0:\n",
    "        messages = get_last_ten_messages_from_sqs_queue(jobs_queue_name, 300)\n",
    "        result_messages = []\n",
    "        for message in messages:\n",
    "            message_body = json.loads(message.body)\n",
    "            left_slice = np.array(message_body['left-slice'])\n",
    "            right_slice = np.array(message_body['right-slice'])\n",
    "            result = np.dot(left_slice, right_slice)\n",
    "            result_message_body = {\n",
    "                'i': message_body['i'],\n",
    "                'j': message_body['j'],\n",
    "                'result': result.tolist()\n",
    "            }\n",
    "            json_result_message_body = json.dumps(result_message_body)\n",
    "            result_messages.append(json_result_message_body)\n",
    "        try:\n",
    "            send_bulk_messages_to_sqs_queue(results_queue_name, result_messages, 'result')\n",
    "            for message in messages:\n",
    "                delete_message_from_sqs_queue(jobs_queue_name, message.receipt_handle)\n",
    "        except:\n",
    "            print('Error while sending messages to the results queue.')\n",
    "            break\n",
    "    print('The jobs queue is empty. All jobs have geen gathered and sent to the results queue.')\n",
    "\n",
    "gather_jobs_then_compute_and_send_results(queues_names[0], queues_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gather_results_and_reconstruct_matrix(results_queue_name, result_matrix_shape):\n",
    "    result_matrix = np.empty((result_matrix_shape, result_matrix_shape), dtype=np.ndarray)\n",
    "    while get_amount_of_available_messages_in_sqs_queue(results_queue_name) > 0 or get_amount_of_in_flight_messages_in_sqs_queue(results_queue_name) > 0:\n",
    "        messages = get_last_ten_messages_from_sqs_queue(results_queue_name, 300)\n",
    "        for message in messages:\n",
    "            message_body = json.loads(message.body)\n",
    "            result_matrix[message_body['i']][message_body['j']] = np.array(message_body['result'])\n",
    "            delete_message_from_sqs_queue(results_queue_name, message.receipt_handle)\n",
    "    result_matrix = np.concatenate([np.concatenate([result_matrix[i][j] for j in range(result_matrix_shape)], axis=1) for i in range(result_matrix_shape)], axis=0)\n",
    "    print('The results queue is empty. All results have been gathered and the result matrix has been reconstructed.')\n",
    "    return result_matrix\n",
    "\n",
    "result_matrix = gather_results_and_reconstruct_matrix(queues_names[1], blocks.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('The result matrix is equal to the self computed product: ' + str(np.array_equal(result_matrix, np.dot(matrix, matrix))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CLEAN-UP:\n",
    "for queue_name in queues_names:\n",
    "    purge_queue(queue_name)\n",
    "    delete_sqs_queue(queue_name)\n",
    "# for instances_name in instances_names:\n",
    "#     stop_instance_by_name(instances_name)\n",
    "#     terminate_instance_by_name(instances_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
