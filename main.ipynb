{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cloud Computing Assignment 2022-2023\n",
    "Implementation of an application processing large data sets in parallel on a distributed Cloud environment (ie. AWS)\n",
    "\n",
    "Â© Copyright 2022, All rights reserved to Hans Haller, CSTE-CIDA Student at Cranfield Uni. SATM, Cranfield, UK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Solution setup - Pre-requisites:\n",
    "1. Make sure the aws credentials taken from the Learner Lab are updated in the ~/.aws/credentials file (Test connection locally using aws sts get-caller-identity)\n",
    "2. Specify the \"labsuser.pem\" perm-key's (taken from the Learner Lab) path, needed by paramiko to connect to the EC2 instances and execute ssh commands.\n",
    "3. Create EC2, S3 and SQS resources and clients using boto3.\n",
    "### Solution setup steps (Using Boto3):\n",
    "1. Create a cluster of EC2 instances on AWS, using the AWS Linux 2 images.\n",
    "2. Create a S3 bucket to store the data.\n",
    "3. Create a SQS queue to store stacks of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### IMPORTS:\n",
    "\n",
    "The following controllers defines functions that use boto3 packaged functions to make AWS API calls. By importing the controllers, a Boto3 resource is automatically created for each AWS service that is needd for the solution (EC2, SQS, SSM, S3, etc) in order for these functions to work.\n",
    "\n",
    "The Boto3 resources uses the AWS credentials that are located in the .aws local folder of the user who executes this software.\n",
    "\n",
    "As a result, it is important that they are updated before running the following. Thus please make sure to restart the kernel and re-execute the imports if the credentials expired (ie. the Learner Lab session ended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CONTROLLERS=\n",
    "from backend.controllers.boto3_controller import *\n",
    "from backend.controllers.ec2_controller import *\n",
    "from backend.controllers.matrix_controller import *\n",
    "from backend.controllers.s3_controller import *\n",
    "from backend.controllers.spark_controller import *\n",
    "from backend.controllers.sqs_controller import *\n",
    "from backend.controllers.ssm_controller import *\n",
    "from backend.controllers.app_controller import *\n",
    "\n",
    "# SERVICES=\n",
    "from backend.work_service import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Replace every pre-steps of exec_shell() with the following procedure:\n",
    "# Create a setup.sh script that installs all the packages needed for the application to run, and then execute it on each instance.\n",
    "\n",
    "# TODO (BONUS): BULK VERIFICATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AWS - SOLUTION SETUP AND TASKS EXECUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SETTINGS=\n",
    "worker_amount = 2\n",
    "backend_path = os.path.join(os.getcwd(), 'backend')     # !! IMPORTANT: Make sure to update this path to the backend folder of the project !!\n",
    "\n",
    "# NAMES=\n",
    "instances_names = np.concatenate((np.array(['master']), np.array(['worker' + str(i) for i in range(1, worker_amount+1)]))).tolist()\n",
    "queues_names = ['main-protected-jobs.fifo', 'main-protected-results.fifo']\n",
    "bucket_name = 'main-protected-bucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ENVIRONMENT SETUP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# START TIMER:\n",
    "print('Beginning AWS environment setup. Starting timer...')\n",
    "envsetup_timer = time.time()\n",
    "\n",
    "# SQS QUEUES:\n",
    "create_sqs_queues(queues_names)\n",
    "# S3 BUCKET:\n",
    "create_s3_bucket(bucket_name)\n",
    "# EC2 INSTANCES:\n",
    "create_instances_and_wait_for_running(instances_names)\n",
    "\n",
    "# SEND BACKEND FOLDER -> S3 BUCKET -> EC2 INSTANCES:\n",
    "upload_dir_to_s3(backend_path, bucket_name, 'backend')\n",
    "\n",
    "# INSTALL PACKAGES ON EC2 INSTANCES (SEND COMMANDS & RUNS IN THE BACKGROUND)\n",
    "instances_ids = get_instance_ids_by_names(instances_names)\n",
    "commands = [\n",
    "    'aws s3 sync s3://' + bucket_name + '/backend /home/ec2-user/backend',\n",
    "    'cd /home/ec2-user/backend && sudo mkdir data && cd data && sudo mkdir input && sudo mkdir output && cd output && sudo mkdir mx && sudo mkdir add',\n",
    "    'sudo yum install tree -y',\n",
    "    'pip3 install boto3',\n",
    "    'pip3 install numpy',\n",
    "    'pip3 install pandas'\n",
    "]\n",
    "responses = exec_SSHs_on_instances_using_SSM(instances_ids, commands)\n",
    "\n",
    "# UPDATE PACKAGES ON EC2 INSTANCES:\n",
    "update_instances_credentials_using_boto3_session_credentials(get_instance_ids_by_names(instances_names))\n",
    "\n",
    "# STOP TIMER:\n",
    "print('Environment setup took: ' + str(np.round(time.time() - envsetup_timer, 2)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SEND BACKEND FOLDER -> S3 BUCKET -> EC2 INSTANCES:\n",
    "instances_ids = get_instance_ids_by_names(instances_names)\n",
    "upload_dir_to_s3(backend_path, bucket_name, 'backend')\n",
    "exec_SSHs_on_instances_using_SSM(instances_ids, ['rm -rf /home/ec2-user/backend', 'aws s3 sync s3://' + bucket_name + '/backend /home/ec2-user/backend', 'cd /home/ec2-user/backend && sudo mkdir data && cd data && sudo mkdir input && sudo mkdir output && cd output && sudo mkdir mx && sudo mkdir add'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "view_all_instances(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create_matrix_then_split_and_send_jobs(matrix_shape, queues_names[0], bucket_name)\n",
    "# gather_jobs_then_compute_and_send_results(queues_names[0], queues_names[1])\n",
    "# gather_results_and_reconstruct_matrix(queues_names[1], bucket_name)\n",
    "# verify_result_matrix(bucket_name, '707566791', 'mx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SOLUTION EXECUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PREFERENCES=\n",
    "matrix_shape = 500\n",
    "used_workers = 1\n",
    "\n",
    "sol_timer = time.time()\n",
    "\n",
    "# JOB: CREATE A MATRIX, SPLIT IT INTO SLICES, AND SEND THE SLICES TO THE JOBS QUEUE:\n",
    "command = 'sudo python3 backend/work_service.py create ' + str(matrix_shape) + ' ' + queues_names[0] + ' ' + bucket_name\n",
    "stdout, stderr = exec_SSH_on_instance(instances_names[0], command)\n",
    "outprint(stdout, stderr)\n",
    "\n",
    "# JOB: GATHER JOBS FROM THE JOBS QUEUE, COMPUTE THE RESULTS, AND SEND THE RESULTS TO THE RESULTS QUEUE:\n",
    "for instance_name in instances_names[1:used_workers+1]:\n",
    "    command = 'sudo python3 backend/work_service.py getjobs ' + queues_names[0] + ' ' + queues_names[1]\n",
    "    stdout, stderr = exec_SSH_on_instance(instance_name, command)\n",
    "    outprint(stdout, stderr)\n",
    "\n",
    "# JOB: GATHER RESULTS FROM THE RESULTS QUEUE, AND RECONSTRUCT THE RESULT MATRIX:\n",
    "command = 'sudo python3 backend/work_service.py getresults ' + queues_names[1] + ' ' + bucket_name\n",
    "stdout, stderr = exec_SSH_on_instance(instances_names[0], command)\n",
    "outprint(stdout, stderr)\n",
    "\n",
    "print('The computation took: ' + str(np.round(time.time() - sol_timer, 2)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id = '59993422'\n",
    "op = 'mx'\n",
    "# JOB: VERIFY THE RESULTS COMPUTED ON AWS DISTRIBUTED CLOUD ENVIRONMENT, USING NUMPY'S MATRIX/ADD FUNCTIONS:\n",
    "command = 'sudo python3 backend/work_service.py verify ' + bucket_name + ' ' + id + ' ' + op\n",
    "stdout, stderr = exec_SSH_on_instance(instances_names[0], command)\n",
    "outprint(stdout, stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CLEAN UP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for queue_name in queues_names:\n",
    "    purge_queue(queue_name)\n",
    "    delete_sqs_queue(queue_name)\n",
    "for instances_name in instances_names:\n",
    "    stop_instance_by_name(instances_name)\n",
    "    terminate_instance_by_name(instances_name)\n",
    "delete_s3_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
