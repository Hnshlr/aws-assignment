{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cloud Computing Assignment 2022-2023\n",
    "Implementation of an application processing large data sets in parallel on a distributed Cloud environment (ie. AWS)\n",
    "\n",
    "Â© Copyright 2022, All rights reserved to Hans Haller, CSTE-CIDA Student at Cranfield Uni. SATM, Cranfield, UK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Solution setup - Pre-requisites:\n",
    "1. Make sure the aws credentials taken from the Learner Lab are updated in the ~/.aws/credentials file (Test connection locally using aws sts get-caller-identity)\n",
    "2. Specify the \"labsuser.pem\" perm-key's (taken from the Learner Lab) path, needed by paramiko to connect to the EC2 instances and execute ssh commands.\n",
    "3. Create EC2, S3 and SQS resources and clients using boto3.\n",
    "### Solution setup steps (Using Boto3):\n",
    "1. Create a cluster of EC2 instances on AWS, using the AWS Linux 2 images.\n",
    "2. Create a S3 bucket to store the data.\n",
    "3. Create a SQS queue to store stacks of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### IMPORTS:\n",
    "\n",
    "The following controllers defines functions that use boto3 packaged functions to make AWS API calls. By importing the controllers, a Boto3 resource is automatically created for each element of the solution (EC2, SQS, SSM, S3, etc) in order for these functions to work. The Boto3 resources uses the AWS credentials that are located in the .aws local folder of the user who executes this software. As a result, it is important that they are updated before running the following. Thus please make sure to restart the kernel and re-execute the imports if the credentials expired (ie. the Learner Lab session ended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from backend.controllers.boto3_controller import *\n",
    "from backend.controllers.ec2_controller import *\n",
    "from backend.controllers.matrix_controller import *\n",
    "from backend.controllers.s3_controller import *\n",
    "from backend.controllers.spark_controller import *\n",
    "from backend.controllers.sqs_controller import *\n",
    "from backend.controllers.ssm_controller import *\n",
    "from backend.controllers.app_controller import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from backend.work_service import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Replace every pre-steps of exec_shell() with the following procedure:\n",
    "# Create a setup.sh script that installs all the packages needed for the application to run, and then execute it on each instance.\n",
    "\n",
    "# TODO (BONUS): BULK VERIFICATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AWS - SOLUTION SETUP AND TASKS EXECUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SETTINGS=\n",
    "worker_amount = 2\n",
    "matrix_shape = 1000\n",
    "backend_path = os.path.join(os.getcwd(), 'backend')     # !! IMPORTANT: Make sure to update this path to the backend folder of the project !!\n",
    "\n",
    "# NAMES=\n",
    "instances_names = np.concatenate((np.array(['master']), np.array(['worker' + str(i) for i in range(1, worker_amount+1)]))).tolist()\n",
    "queues_names = ['main-protected-jobs.fifo', 'main-protected-results.fifo']\n",
    "bucket_name = 'main-protected-bucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# EC2 INSTANCES:\n",
    "create_instances_and_wait_for_running(instances_names)\n",
    "# SQS QUEUES:\n",
    "create_sqs_queues(queues_names)\n",
    "# S3 BUCKET:\n",
    "create_s3_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(get_instance_public_dns_by_name(instances_names[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ENVIRONMENT SETUP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# S3 & EC2 - BACKEND FOLDER SETUP:\n",
    "# UPLOAD BACKEND FOLDER -> S3 BUCKET:\n",
    "upload_dir_to_s3(backend_path, bucket_name, 'backend')\n",
    "for instance_name in instances_names:\n",
    "    # DOWNLOAD BACKEND FOLDER : S3 BUCKET -> EC2 INSTANCES:\n",
    "    download_directory_on_instance_from_s3_bucket(instance_name, bucket_name, 'backend', 'backend')\n",
    "    # CREATE THE TEMP DATA/INPUT AND DATA/OUTPUT DIRECTORIES:\n",
    "    exec_SSH_on_instance(instance_name, 'cd backend && mkdir data && cd data && mkdir input && mkdir output && cd output && mkdir mx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# EC2 INSTANCES - PACKAGE DOWNLOAD:\n",
    "for instance_name in instances_names:\n",
    "    update_instance_credentials_using_boto3_session_credentials(instance_name)\n",
    "    exec_SSH_on_instance(instance_name, 'sudo yum install tree -y')\n",
    "    exec_SSH_on_instance(instance_name, 'pip3 install boto3')\n",
    "    exec_SSH_on_instance(instance_name, 'pip3 install numpy')\n",
    "    exec_SSH_on_instance(instance_name, 'pip3 install pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create_matrix_then_split_and_send_jobs(matrix_shape, queues_names[0], bucket_name)\n",
    "# gather_jobs_then_compute_and_send_results(queues_names[0], queues_names[1])\n",
    "# gather_results_and_reconstruct_matrix(queues_names[1], bucket_name)\n",
    "# verify_result_matrix(bucket_name, '707566791', 'mx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SOLUTION EXECUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# JOB: CREATE A MATRIX, SPLIT IT INTO SLICES, AND SEND THE SLICES TO THE JOBS QUEUE:\n",
    "command = 'python3 backend/work_service.py create ' + str(matrix_shape) + ' ' + queues_names[0] + ' ' + bucket_name\n",
    "stdout, stderr = exec_SSH_on_instance(instances_names[0], command)\n",
    "outprint(stdout, stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# JOB: GATHER JOBS FROM THE JOBS QUEUE, COMPUTE THE RESULTS, AND SEND THE RESULTS TO THE RESULTS QUEUE:\n",
    "for instance_name in instances_names[1:2]:\n",
    "    command = 'python3 backend/work_service.py getjobs ' + queues_names[0] + ' ' + queues_names[1]\n",
    "    stdout, stderr = exec_SSH_on_instance(instance_name, command)\n",
    "    outprint(stdout, stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# JOB: GATHER RESULTS FROM THE RESULTS QUEUE, AND RECONSTRUCT THE RESULT MATRIX:\n",
    "command = 'python3 backend/work_service.py getresults ' + queues_names[1] + ' ' + bucket_name\n",
    "stdout, stderr = exec_SSH_on_instance(instances_names[0], command)\n",
    "outprint(stdout, stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Computation time: ' + str(time.time() - start_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# JOB: CREATE A MATRIX, SPLIT IT INTO SLICES, AND SEND THE SLICES TO THE JOBS QUEUE:\n",
    "command = 'python3 backend/work_service.py create ' + str(matrix_shape) + ' ' + queues_names[0] + ' ' + bucket_name\n",
    "stdout, stderr = exec_SSH_on_instance(instances_names[0], command)\n",
    "# JOB: GATHER JOBS FROM THE JOBS QUEUE, COMPUTE THE RESULTS, AND SEND THE RESULTS TO THE RESULTS QUEUE:\n",
    "for instance_name in instances_names[1:]:\n",
    "    command = 'python3 backend/work_service.py getjobs ' + queues_names[0] + ' ' + queues_names[1]\n",
    "    exec_SSH_on_instance_no_wait(instance_name, command)\n",
    "# JOB: GATHER RESULTS FROM THE RESULTS QUEUE, AND RECONSTRUCT THE RESULT MATRIX:\n",
    "command = 'python3 backend/work_service.py getresults ' + queues_names[1] + ' ' + bucket_name\n",
    "exec_SSH_on_instance(instances_names[0], command)\n",
    "print('Computation time: ' + str(np.round(time.time() - start_time, 2)) + ' seconds.')\n",
    "\n",
    "# To fix, make infinite loop in the getjobs function, and add a break condition when the process received as much blocks as it should have received.\n",
    "# The job amount can be known at any time as it is in the body of every SQS message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id = '117988589'\n",
    "op = 'mx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# JOB: VERIFY THE RESULTS COMPUTED ON AWS DISTRIBUTED CLOUD ENVIRONMENT, USING NUMPY'S MATRIX/ADD FUNCTIONS:\n",
    "command = 'python3 backend/work_service.py verify ' + bucket_name + ' ' + id + ' ' + op\n",
    "stdout, stderr = exec_SSH_on_instance(instances_names[0], command)\n",
    "outprint(stdout, stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CLEAN UP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for queue_name in queues_names:\n",
    "    purge_queue(queue_name)\n",
    "    delete_sqs_queue(queue_name)\n",
    "for instances_name in instances_names:\n",
    "    stop_instance_by_name(instances_name)\n",
    "    terminate_instance_by_name(instances_name)\n",
    "delete_s3_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
